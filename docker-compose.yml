version: '3.8'

services:
  auth:
    container_name: crm_auth
    build:
      # El contexto es el directorio raíz (donde está este archivo).
      context: .
      # La ruta explícita al Dockerfile que debe usar.
      dockerfile: ./auth-service/Dockerfile
    restart: unless-stopped
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgres://consilium_user:supersecretpassword@crm_db:5432/consilium_db
      - PORT=3000
      - JWT_SECRET=este-es-un-secreto-muy-largo-y-dificil-de-adivinar
    depends_on:
      db:
        condition: service_healthy
    networks:
      # Lo conectamos a ambas redes
      - proxy-net
      - crm-internal

  db:
    container_name: crm_db
    build:
      context: ./auth-service/database
      # La ruta explícita al Dockerfile que debe usar.
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      - POSTGRES_USER=consilium_user
      - POSTGRES_PASSWORD=supersecretpassword
      - POSTGRES_DB=consilium_db
    # SECCIÓN DE VOLÚMENES PARA LA BASE DE DATOS (ESTA ES LA CORRECTA)
    volumes:
      # Este volumen guarda los datos de la BD de forma persistente
      - pgdata:/var/lib/postgresql/data
    networks:
      - crm-internal
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U consilium_user -d consilium_db"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s # Le damos 20s para que arranque antes de que los fallos cuenten
  
  frontend:
    container_name: crm_frontend
    build:
      context: ./frontend-service
      dockerfile: Dockerfile
    restart: unless-stopped
    networks:
      # Solo necesita estar en la red del proxy para ser accesible desde el exterior
      - proxy-net

# CLAVE: Definimos el volumen 'pgdata' para que Docker lo gestione
volumes:
  pgdata:

networks:
  proxy-net:
    external: true
  crm-internal:
    driver: bridge
